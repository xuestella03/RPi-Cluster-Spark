
- name: Copy application files and run TPC-H script
  hosts: server
  become: no
  vars:
    # fix this
    app_dir: "{{ ansible_env.HOME }}/Documents/Repositories/RPi-Cluster-Spark/tpch"
  tasks:
    - name: Create application directory
      file:
        path: "{{ app_dir }}"
        state: directory
        mode: '0755'
        
    - name: Copy Python scripts
      copy:
        src: "{{ item }}"
        dest: "{{ app_dir }}/{{ item }}"
        mode: '0644'
      loop:
        - run_tpch.py
        - config.py
        - load_data.py
        - queries.py
      when: item is file
      
    # Don't need this with NFS
    # - name: Copy data files if they exist
    #   synchronize:
    #     src: ../../data/
    #     dest: "{{ app_dir }}/data/"
    #     recursive: yes
    #   when: lookup('fileglob', '../../data/*') | length > 0
    #   ignore_errors: yes
      
    - name: Run TPC-H benchmark script
      shell: |
        source /etc/profile.d/spark.sh
        python3 run_tpch.py
      args:
        chdir: "{{ app_dir }}"
        executable: /bin/bash
      environment:
        SPARK_HOME: /opt/spark
        PYTHONPATH: "{{ app_dir }}"
      register: tpch_output
      
    - name: Display TPC-H output
      debug:
        msg: "{{ tpch_output.stdout_lines }}"
        
    - name: Display any errors
      debug:
        msg: "{{ tpch_output.stderr_lines }}"
      when: tpch_output.stderr_lines | length > 0
  
    - name: Run TPC-H benchmark script again
      shell: |
        source /etc/profile.d/spark.sh
        python3 run_tpch.py
      args:
        chdir: "{{ app_dir }}"
        executable: /bin/bash
      environment:
        SPARK_HOME: /opt/spark
        PYTHONPATH: "{{ app_dir }}"
      register: tpch_output
      
    - name: Display TPC-H output
      debug:
        msg: "{{ tpch_output.stdout_lines }}"
        
    - name: Display any errors
      debug:
        msg: "{{ tpch_output.stderr_lines }}"
      when: tpch_output.stderr_lines | length > 0

    - name: Run TPC-H benchmark script again
      shell: |
        source /etc/profile.d/spark.sh
        python3 run_tpch.py
      args:
        chdir: "{{ app_dir }}"
        executable: /bin/bash
      environment:
        SPARK_HOME: /opt/spark
        PYTHONPATH: "{{ app_dir }}"
      register: tpch_output
      
    - name: Display TPC-H output
      debug:
        msg: "{{ tpch_output.stdout_lines }}"
        
    - name: Display any errors
      debug:
        msg: "{{ tpch_output.stderr_lines }}"
      when: tpch_output.stderr_lines | length > 0
    
    - name: Run TPC-H benchmark script again
      shell: |
        source /etc/profile.d/spark.sh
        python3 run_tpch.py
      args:
        chdir: "{{ app_dir }}"
        executable: /bin/bash
      environment:
        SPARK_HOME: /opt/spark
        PYTHONPATH: "{{ app_dir }}"
      register: tpch_output
      
    - name: Display TPC-H output
      debug:
        msg: "{{ tpch_output.stdout_lines }}"
        
    - name: Display any errors
      debug:
        msg: "{{ tpch_output.stderr_lines }}"
      when: tpch_output.stderr_lines | length > 0

    - name: Run TPC-H benchmark script again
      shell: |
        source /etc/profile.d/spark.sh
        python3 run_tpch.py
      args:
        chdir: "{{ app_dir }}"
        executable: /bin/bash
      environment:
        SPARK_HOME: /opt/spark
        PYTHONPATH: "{{ app_dir }}"
      register: tpch_output
      
    - name: Display TPC-H output
      debug:
        msg: "{{ tpch_output.stdout_lines }}"
        
    - name: Display any errors
      debug:
        msg: "{{ tpch_output.stderr_lines }}"
      when: tpch_output.stderr_lines | length > 0