# Start the Spark Master and Workers.
# Right now a lot of this stuff is hardcoded (JAVA_HOME especially) 
# so I need to fix that.

# Also, killing the process and restarting the spark master fails
# every other time (the starting after the stop fails)
# need to fix

- name: Start Spark master
  hosts: server
  become: yes
  tasks:
    - name: Update spark-env.sh with server JAVA_HOME  # change to not hardcoded
    # just shell run echo $JAVA_HOME and save that?
      copy:
        dest: /opt/spark/conf/spark-env.sh
        content: |
          #!/usr/bin/env bash
          export JAVA_HOME=/usr/lib/jvm/java-1.21.0-openjdk-amd64 
          export SPARK_MASTER_HOST={{ ansible_default_ipv4.address }}
          export SPARK_MASTER_PORT=7077
          export SPARK_MASTER_WEBUI_PORT=8080
        mode: '0755'
        
    - name: Kill any existing Spark processes
      shell: pkill -f org.apache.spark.deploy
      ignore_errors: yes
      
    - name: Start Spark master
      shell: |
        export SPARK_HOME=/opt/spark
        export JAVA_HOME=/usr/lib/jvm/java-1.21.0-openjdk-amd64
        /opt/spark/sbin/start-master.sh
        sleep 5
      register: master_start
      
    - name: Check if master is running
      shell: ps aux | grep org.apache.spark.deploy.master.Master | grep -v grep
      register: master_check
      
    - name: Display master process
      debug:
        msg: "Master is running"
      
    - name: Check if port 7077 is listening
      wait_for:
        host: "{{ ansible_default_ipv4.address }}"
        port: 7077
        timeout: 10
        
    - name: Success message
      debug:
        msg: 
          - "Spark Master started successfully!"
          - "Master URL: spark://{{ ansible_default_ipv4.address }}:7077"
          - "Web UI: http://{{ ansible_default_ipv4.address }}:8080"

- name: Start Spark workers
  hosts: workers
  become: yes
  tasks:
    - name: Update spark-env.sh for workers with /opt/semeru # change to not hardcoded
      copy:
        dest: /opt/spark/conf/spark-env.sh
        content: |
          #!/usr/bin/env bash
          export JAVA_HOME=/opt/semeru
          export SPARK_WORKER_CORES=4
          export SPARK_WORKER_MEMORY=4g
        mode: '0755'
        
    - name: Get master IP
      set_fact:
        master_ip: "{{ hostvars[groups['server'][0]]['ansible_default_ipv4']['address'] }}"
        
    - name: Kill any existing Spark worker processes
      shell: pkill -f org.apache.spark.deploy.worker
      ignore_errors: yes
      
    - name: Start Spark worker
      shell: |
        export SPARK_HOME=/opt/spark
        export JAVA_HOME=/opt/semeru
        /opt/spark/sbin/start-worker.sh spark://{{ master_ip }}:7077
        sleep 3
      register: worker_start
      
    - name: Check if worker is running
      shell: ps aux | grep org.apache.spark.deploy.worker.Worker | grep -v grep
      register: worker_check
      
    - name: Display worker process
      debug:
        msg: "Worker is running"
      when: worker_check.rc == 0
        
    - name: Show worker log if failed
      shell: tail -50 /opt/spark/logs/*Worker*.out
      register: worker_log
      when: worker_check.rc != 0
      ignore_errors: yes
      
    - name: Display worker log on failure
      debug:
        msg: "{{ worker_log.stdout_lines }}"
      when: worker_check.rc != 0
        
    - name: Success message
      debug:
        msg: "Worker connected to spark://{{ master_ip }}:7077"
      when: worker_check.rc == 0
- name: Wait for cluster to be fully ready
  hosts: server
  tasks:
    - name: Wait for master web UI
      wait_for:
        port: 8080
        delay: 5
        timeout: 30
        
    - name: Pause for workers to register
      pause:
        seconds: 15
        prompt: "Waiting for workers to register..."
